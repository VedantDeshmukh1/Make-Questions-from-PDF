{
  "cells": [
    {
      "cell_type": "code",
      "execution_count": 2,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "-FIcBBmiKLsc",
        "outputId": "c9c66ee7-f8bb-4627-8ed7-64292208a820"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting langchain\n",
            "  Downloading langchain-0.1.16-py3-none-any.whl (817 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m817.7/817.7 kB\u001b[0m \u001b[31m4.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: PyYAML>=5.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (6.0.1)\n",
            "Requirement already satisfied: SQLAlchemy<3,>=1.4 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.0.29)\n",
            "Requirement already satisfied: aiohttp<4.0.0,>=3.8.3 in /usr/local/lib/python3.10/dist-packages (from langchain) (3.9.5)\n",
            "Requirement already satisfied: async-timeout<5.0.0,>=4.0.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (4.0.3)\n",
            "Collecting dataclasses-json<0.7,>=0.5.7 (from langchain)\n",
            "  Downloading dataclasses_json-0.6.4-py3-none-any.whl (28 kB)\n",
            "Collecting jsonpatch<2.0,>=1.33 (from langchain)\n",
            "  Downloading jsonpatch-1.33-py2.py3-none-any.whl (12 kB)\n",
            "Collecting langchain-community<0.1,>=0.0.32 (from langchain)\n",
            "  Downloading langchain_community-0.0.33-py3-none-any.whl (1.9 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.9/1.9 MB\u001b[0m \u001b[31m27.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-core<0.2.0,>=0.1.42 (from langchain)\n",
            "  Downloading langchain_core-0.1.44-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.2/290.2 kB\u001b[0m \u001b[31m23.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting langchain-text-splitters<0.1,>=0.0.1 (from langchain)\n",
            "  Downloading langchain_text_splitters-0.0.1-py3-none-any.whl (21 kB)\n",
            "Collecting langsmith<0.2.0,>=0.1.17 (from langchain)\n",
            "  Downloading langsmith-0.1.49-py3-none-any.whl (115 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m115.2/115.2 kB\u001b[0m \u001b[31m1.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: numpy<2,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (1.25.2)\n",
            "Requirement already satisfied: pydantic<3,>=1 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.7.0)\n",
            "Requirement already satisfied: requests<3,>=2 in /usr/local/lib/python3.10/dist-packages (from langchain) (2.31.0)\n",
            "Requirement already satisfied: tenacity<9.0.0,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from langchain) (8.2.3)\n",
            "Requirement already satisfied: aiosignal>=1.1.2 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.3.1)\n",
            "Requirement already satisfied: attrs>=17.3.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (23.2.0)\n",
            "Requirement already satisfied: frozenlist>=1.1.1 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.4.1)\n",
            "Requirement already satisfied: multidict<7.0,>=4.5 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (6.0.5)\n",
            "Requirement already satisfied: yarl<2.0,>=1.0 in /usr/local/lib/python3.10/dist-packages (from aiohttp<4.0.0,>=3.8.3->langchain) (1.9.4)\n",
            "Collecting marshmallow<4.0.0,>=3.18.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading marshmallow-3.21.1-py3-none-any.whl (49 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m49.4/49.4 kB\u001b[0m \u001b[31m3.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting typing-inspect<1,>=0.4.0 (from dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading typing_inspect-0.9.0-py3-none-any.whl (8.8 kB)\n",
            "Collecting jsonpointer>=1.9 (from jsonpatch<2.0,>=1.33->langchain)\n",
            "  Downloading jsonpointer-2.4-py2.py3-none-any.whl (7.8 kB)\n",
            "Collecting packaging<24.0,>=23.2 (from langchain-core<0.2.0,>=0.1.42->langchain)\n",
            "  Downloading packaging-23.2-py3-none-any.whl (53 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m53.0/53.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting orjson<4.0.0,>=3.9.14 (from langsmith<0.2.0,>=0.1.17->langchain)\n",
            "  Downloading orjson-3.10.1-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (141 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m141.1/141.1 kB\u001b[0m \u001b[31m8.4 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (2.18.1)\n",
            "Requirement already satisfied: typing-extensions>=4.6.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1->langchain) (4.11.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2->langchain) (2024.2.2)\n",
            "Requirement already satisfied: greenlet!=0.4.17 in /usr/local/lib/python3.10/dist-packages (from SQLAlchemy<3,>=1.4->langchain) (3.0.3)\n",
            "Collecting mypy-extensions>=0.3.0 (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7,>=0.5.7->langchain)\n",
            "  Downloading mypy_extensions-1.0.0-py3-none-any.whl (4.7 kB)\n",
            "Installing collected packages: packaging, orjson, mypy-extensions, jsonpointer, typing-inspect, marshmallow, jsonpatch, langsmith, dataclasses-json, langchain-core, langchain-text-splitters, langchain-community, langchain\n",
            "  Attempting uninstall: packaging\n",
            "    Found existing installation: packaging 24.0\n",
            "    Uninstalling packaging-24.0:\n",
            "      Successfully uninstalled packaging-24.0\n",
            "Successfully installed dataclasses-json-0.6.4 jsonpatch-1.33 jsonpointer-2.4 langchain-0.1.16 langchain-community-0.0.33 langchain-core-0.1.44 langchain-text-splitters-0.0.1 langsmith-0.1.49 marshmallow-3.21.1 mypy-extensions-1.0.0 orjson-3.10.1 packaging-23.2 typing-inspect-0.9.0\n"
          ]
        }
      ],
      "source": [
        "!pip install langchain"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 3,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NPx5Z7g9KXIX",
        "outputId": "161df916-5426-4d79-f5ef-553e0475d2b4"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting pypdf\n",
            "  Downloading pypdf-4.2.0-py3-none-any.whl (290 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m290.4/290.4 kB\u001b[0m \u001b[31m2.6 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: typing_extensions>=4.0 in /usr/local/lib/python3.10/dist-packages (from pypdf) (4.11.0)\n",
            "Installing collected packages: pypdf\n",
            "Successfully installed pypdf-4.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install pypdf"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 4,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "jqe8T_1yLtGz",
        "outputId": "3a54c3f5-3bb9-428d-c3d2-e0c9977f170e"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting openai\n",
            "  Downloading openai-1.23.1-py3-none-any.whl (310 kB)\n",
            "\u001b[?25l     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m0.0/311.0 kB\u001b[0m \u001b[31m?\u001b[0m eta \u001b[36m-:--:--\u001b[0m\r\u001b[2K     \u001b[91m━━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[90m╺\u001b[0m\u001b[90m━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m163.8/311.0 kB\u001b[0m \u001b[31m4.9 MB/s\u001b[0m eta \u001b[36m0:00:01\u001b[0m\r\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m311.0/311.0 kB\u001b[0m \u001b[31m6.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: anyio<5,>=3.5.0 in /usr/local/lib/python3.10/dist-packages (from openai) (3.7.1)\n",
            "Requirement already satisfied: distro<2,>=1.7.0 in /usr/lib/python3/dist-packages (from openai) (1.7.0)\n",
            "Collecting httpx<1,>=0.23.0 (from openai)\n",
            "  Downloading httpx-0.27.0-py3-none-any.whl (75 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m75.6/75.6 kB\u001b[0m \u001b[31m9.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: pydantic<3,>=1.9.0 in /usr/local/lib/python3.10/dist-packages (from openai) (2.7.0)\n",
            "Requirement already satisfied: sniffio in /usr/local/lib/python3.10/dist-packages (from openai) (1.3.1)\n",
            "Requirement already satisfied: tqdm>4 in /usr/local/lib/python3.10/dist-packages (from openai) (4.66.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.7 in /usr/local/lib/python3.10/dist-packages (from openai) (4.11.0)\n",
            "Requirement already satisfied: idna>=2.8 in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (3.7)\n",
            "Requirement already satisfied: exceptiongroup in /usr/local/lib/python3.10/dist-packages (from anyio<5,>=3.5.0->openai) (1.2.0)\n",
            "Requirement already satisfied: certifi in /usr/local/lib/python3.10/dist-packages (from httpx<1,>=0.23.0->openai) (2024.2.2)\n",
            "Collecting httpcore==1.* (from httpx<1,>=0.23.0->openai)\n",
            "  Downloading httpcore-1.0.5-py3-none-any.whl (77 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m77.9/77.9 kB\u001b[0m \u001b[31m10.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting h11<0.15,>=0.13 (from httpcore==1.*->httpx<1,>=0.23.0->openai)\n",
            "  Downloading h11-0.14.0-py3-none-any.whl (58 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m58.3/58.3 kB\u001b[0m \u001b[31m8.5 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: annotated-types>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (0.6.0)\n",
            "Requirement already satisfied: pydantic-core==2.18.1 in /usr/local/lib/python3.10/dist-packages (from pydantic<3,>=1.9.0->openai) (2.18.1)\n",
            "Installing collected packages: h11, httpcore, httpx, openai\n",
            "Successfully installed h11-0.14.0 httpcore-1.0.5 httpx-0.27.0 openai-1.23.1\n"
          ]
        }
      ],
      "source": [
        "!pip install openai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "id": "fG0fMU3sJ4iK"
      },
      "outputs": [],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "\n",
        "loader = PyPDFLoader(\"/content/Big Mac Index.pdf\")\n",
        "pages = loader.load_and_split()"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 22,
      "metadata": {
        "id": "IjujS0C5Cx8J"
      },
      "outputs": [],
      "source": [
        "#KeCZXcIF9UZNDtgfLPAdK9lUIis7rinR\n",
        "import os\n",
        "os.environ['AI21_API_KEY'] = 'YOUR KEY'"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 23,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PexdX4QlDTAi",
        "outputId": "f24a1464-792a-4c84-b3fb-7ce1f4aa20b7"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting ai21\n",
            "  Downloading ai21-2.2.0-py3-none-any.whl (59 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m59.4/59.4 kB\u001b[0m \u001b[31m856.9 kB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting ai21-tokenizer<0.10.0,>=0.9.0 (from ai21)\n",
            "  Downloading ai21_tokenizer-0.9.0-py3-none-any.whl (2.7 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m2.7/2.7 MB\u001b[0m \u001b[31m13.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: dataclasses-json<0.7.0,>=0.6.3 in /usr/local/lib/python3.10/dist-packages (from ai21) (0.6.4)\n",
            "Requirement already satisfied: requests<3.0.0,>=2.31.0 in /usr/local/lib/python3.10/dist-packages (from ai21) (2.31.0)\n",
            "Requirement already satisfied: typing-extensions<5.0.0,>=4.9.0 in /usr/local/lib/python3.10/dist-packages (from ai21) (4.11.0)\n",
            "Collecting sentencepiece<0.3.0,>=0.2.0 (from ai21-tokenizer<0.10.0,>=0.9.0->ai21)\n",
            "  Downloading sentencepiece-0.2.0-cp310-cp310-manylinux_2_17_x86_64.manylinux2014_x86_64.whl (1.3 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m1.3/1.3 MB\u001b[0m \u001b[31m58.8 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tokenizers<0.16.0,>=0.15.2 in /usr/local/lib/python3.10/dist-packages (from ai21-tokenizer<0.10.0,>=0.9.0->ai21) (0.15.2)\n",
            "Requirement already satisfied: marshmallow<4.0.0,>=3.18.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7.0,>=0.6.3->ai21) (3.21.1)\n",
            "Requirement already satisfied: typing-inspect<1,>=0.4.0 in /usr/local/lib/python3.10/dist-packages (from dataclasses-json<0.7.0,>=0.6.3->ai21) (0.9.0)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->ai21) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->ai21) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->ai21) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3.0.0,>=2.31.0->ai21) (2024.2.2)\n",
            "Requirement already satisfied: packaging>=17.0 in /usr/local/lib/python3.10/dist-packages (from marshmallow<4.0.0,>=3.18.0->dataclasses-json<0.7.0,>=0.6.3->ai21) (23.2)\n",
            "Requirement already satisfied: huggingface_hub<1.0,>=0.16.4 in /usr/local/lib/python3.10/dist-packages (from tokenizers<0.16.0,>=0.15.2->ai21-tokenizer<0.10.0,>=0.9.0->ai21) (0.20.3)\n",
            "Requirement already satisfied: mypy-extensions>=0.3.0 in /usr/local/lib/python3.10/dist-packages (from typing-inspect<1,>=0.4.0->dataclasses-json<0.7.0,>=0.6.3->ai21) (1.0.0)\n",
            "Requirement already satisfied: filelock in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->ai21-tokenizer<0.10.0,>=0.9.0->ai21) (3.13.4)\n",
            "Requirement already satisfied: fsspec>=2023.5.0 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->ai21-tokenizer<0.10.0,>=0.9.0->ai21) (2023.6.0)\n",
            "Requirement already satisfied: tqdm>=4.42.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->ai21-tokenizer<0.10.0,>=0.9.0->ai21) (4.66.2)\n",
            "Requirement already satisfied: pyyaml>=5.1 in /usr/local/lib/python3.10/dist-packages (from huggingface_hub<1.0,>=0.16.4->tokenizers<0.16.0,>=0.15.2->ai21-tokenizer<0.10.0,>=0.9.0->ai21) (6.0.1)\n",
            "Installing collected packages: sentencepiece, ai21-tokenizer, ai21\n",
            "  Attempting uninstall: sentencepiece\n",
            "    Found existing installation: sentencepiece 0.1.99\n",
            "    Uninstalling sentencepiece-0.1.99:\n",
            "      Successfully uninstalled sentencepiece-0.1.99\n",
            "Successfully installed ai21-2.2.0 ai21-tokenizer-0.9.0 sentencepiece-0.2.0\n"
          ]
        }
      ],
      "source": [
        "!pip install ai21"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 24,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "KiIDX9M8q3kV",
        "outputId": "11c6eaec-14e8-4056-a465-f67b5de8656b"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions for Text Chunk 1:\n",
            "1. True or False question: The Big Mac Index was introduced in The Economist in September 1986 by Pam Woodall as a semi-humorous illustration of PPP.\n",
            "    2. Multiple Choice Question (MCQ) with four options: In which country is a Big Mac the most expensive as of July 2023?\n",
            "    3. One-word answer question: What is the name of the index that measures the purchasing power parity between currencies?\n",
            "\n",
            "Questions for Text Chunk 2:\n",
            "1. True or False question: \"The Big Mac index was invented by The Economist.\"\n",
            "    2. Multiple Choice Question (MCQ) with four options: \"According to the Big Mac index, the Swiss franc is undervalued by ___% against the US dollar.\"\n",
            "        1. 38.5%\n",
            "        2. 10%\n",
            "        3. 20%\n",
            "        4. 40%\n",
            "    3. One-word answer question: \"Which company first produced the Billy index?\"\n",
            "        1. Bloomberg L.P.\n",
            "        2. The Economist\n",
            "        3. Big Mac index\n",
            "        4. McDonald's\n",
            "\n",
            "Questions for Text Chunk 3:\n",
            "1. True or False question: The Big mac index is limited by geographical coverage.\n",
            "    2. Multiple Choice Question (MCQ) with four options: In which of the following countries is McDonald's present?\n",
            "    a. Netherlands\n",
            "    b. Germany\n",
            "    c. Switzerland\n",
            "    d. Egypt\n",
            "\n",
            "Questions for Text Chunk 4:\n",
            "1. In which of the following years was the BigMac index first mentioned by The Economist?\n",
            "    2. In which year the 200 Argentinean McDonald's restaurants began acting unusually?\n",
            "    3. With reference to BigMac, what does 'value meal' mean?\n",
            "    4. Which of the following statements about the BigMac index is false?\n",
            "      1. The BigMac index supports claims that Argentina's government is cooking the books\n",
            "      2. The BigMac index supports claims that Iceland's government is cooking the books\n",
            "      3. The BigMac index supports claims that Switzerland's government is cooking the books\n",
            "      4. The BigMac index supports claims that Norway's government is cooking the books\n",
            "    5. Which of the following statements about Big Mac sandwiches is false?\n",
            "      1. The BigMac is the same in different countries\n",
            "      2. The BigMac in India is different from the Big Mac in other countries\n",
            "      3. The BigMac in Australia has 22% fewer calories than in Canada\n",
            "      4. The BigMac in Mexico is 8% lighter than in Australia\n",
            "    6. By what percent did the price of a Big Mac value meal rise in June 2012?\n",
            "    7. What serves as the substitute for the BigMac in India?\n",
            "    8. Why, in November 2009, did the three McDonald's in Iceland close?\n",
            "    9. Which of the following statements about the BigMac in Iceland is false?\n",
            "     \n",
            "\n",
            "Questions for Text Chunk 5:\n",
            "1. True or False: The average working time required to buy a Big Mac in Nairobi, Kenya, was 172.6 minutes.\n",
            "    2. Multiple Choice Question (MCQ): This statistic shows the cities where the average working time required to buy a Big Mac was:\n",
            "    a. lowest\n",
            "    b. highest\n",
            "    c. fastest\n",
            "    d. slowest\n",
            "    3. One-word answer: In which year was the first statistic published?\n",
            "    a. 2015\n",
            "    b. 2023\n",
            "    c. 2015\n",
            "    d. 2022\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain.llms import AI21\n",
        "\n",
        "def generate_questions(pdf_path):\n",
        "    # Load the PDF document\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split the text into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Define the prompt template\n",
        "    prompt_template = \"\"\"\n",
        "     Given the following text, generate multiple questions of three or more types as follows:\n",
        "    1. True or False question\n",
        "    2. Multiple Choice Question (MCQ) with four options\n",
        "    3. One-word answer question\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "\n",
        "    Questions:\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "    # Initialize the language model\n",
        "    llm = AI21(model=\"j2-ultra\")\n",
        "\n",
        "    # Create the question generation chain\n",
        "    question_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "    # Generate questions for each text chunk\n",
        "    for i, text in enumerate(texts):\n",
        "        print(f\"Questions for Text Chunk {i+1}:\")\n",
        "        response = question_chain.run(text=text.page_content)\n",
        "        print(response)\n",
        "        print()\n",
        "\n",
        "# Provide the path to your sample PDF file\n",
        "pdf_path = \"/content/Big Mac Index.pdf\"\n",
        "\n",
        "# Generate questions and answers\n",
        "generate_questions(pdf_path)"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 5,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "PLSR49BSLEUF",
        "outputId": "aa9ad6c0-3122-457d-fecc-8587f51618e3"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m146.8/146.8 kB\u001b[0m \u001b[31m2.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m664.5/664.5 kB\u001b[0m \u001b[31m7.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25h"
          ]
        }
      ],
      "source": [
        "!pip install --upgrade --quiet  langchain-google-genai"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 6,
      "metadata": {
        "id": "_Joe_p7jlHus"
      },
      "outputs": [],
      "source": [
        "from langchain_google_genai import GoogleGenerativeAI"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 20,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "_8C_3nzGlR4S",
        "outputId": "01350017-a8e1-4778-9cc8-6410e02960da"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Questions for Text Chunk 1:\n",
            "**True or False Questions**\n",
            "1. The Big Mac Index is a method for measuring the relative cost of goods between countries. (True)\n",
            "2. The Big Mac Index was originally intended as a legitimate tool for exchange rate evaluation. (False)\n",
            "3. The price of a Big Mac is only influenced by the cost of ingredients. (False)\n",
            "\n",
            "**Multiple Choice Questions (MCQ)**\n",
            "1. What is the purpose of the Big Mac Index?\n",
            "   (a) To determine the real exchange rate between currencies\n",
            "   (b) To measure the purchasing power of consumers\n",
            "   (c) To test the validity of purchasing power parity\n",
            "   (d) To track the profitability of McDonald's restaurants\n",
            "\n",
            "2. Which of the following is NOT a factor considered in the Big Mac Index calculation?\n",
            "   (a) Price of ingredients\n",
            "   (b) Local wages\n",
            "   (c) Exchange rates\n",
            "   (d) Cost of advertising\n",
            "\n",
            "3. What is the base country typically used for the Big Mac Index?\n",
            "   (a) Switzerland\n",
            "   (b) United States\n",
            "   (c) United Kingdom\n",
            "   (d) Japan\n",
            "\n",
            "4. Which of the following is a limitation of the Big Mac Index?\n",
            "   (a) It is only applicable to a single product\n",
            "   (b) It does not account for differences in quality\n",
            "   (c) It is subject to currency fluctuations\n",
            "   (d) All of the above\n",
            "\n",
            "**One-word Answer Questions**\n",
            "1. What is the name of the organization that introduced the Big Mac Index? (The Economist)\n",
            "2. What type of economic concept does the Big Mac Index measure? (Purchasing power parity)\n",
            "3. What is the currency unit used in Switzerland? (Swiss franc)\n",
            "\n",
            "Questions for Text Chunk 2:\n",
            "**True or False Questions:**\n",
            "\n",
            "1. The Big Mac index is used to compare the implied exchange rate to the actual exchange rate. (True)\n",
            "2. If the implied exchange rate is less than the actual exchange rate, the currency is overvalued. (False)\n",
            "3. The Swiss franc was overvalued against the US dollar in July 2023 according to the Big Mac index. (True)\n",
            "4. The \"iPod index\" is a variation of the Big Mac index that uses the price of iPods. (True)\n",
            "\n",
            "**Multiple Choice Questions:**\n",
            "\n",
            "1. Which of the following is NOT a variant of the Big Mac index?\n",
            "    (a) Tall Latte index\n",
            "    (b) Billy index\n",
            "    (c) Gold-Mac-Index\n",
            "    (d) Happy Meal index\n",
            "\n",
            "2. What is the purpose of the Big Mac index?\n",
            "    (a) To measure inflation\n",
            "    (b) To compare exchange rates\n",
            "    (c) To determine the value of a country's currency\n",
            "    (d) To estimate the cost of living\n",
            "\n",
            "3. Which of the following factors can affect the accuracy of the Big Mac index?\n",
            "    (a) Shipping costs\n",
            "    (b) Taxes\n",
            "    (c) Local production costs\n",
            "    (d) All of the above\n",
            "\n",
            "4. What does the Latte Line measure?\n",
            "    (a) The correlation between coffee prices and GDP\n",
            "    (b) The number of lattes a person can buy with their salary\n",
            "    (c) The difference between the price of a latte in different countries\n",
            "    (d) The popularity of coffee around the world\n",
            "\n",
            "**One-word Answer Questions:**\n",
            "\n",
            "1. What is the name of the index that compares the price of a Big Mac in different countries?\n",
            "2. What is the unit of measurement used in the Gold-Mac-Index?\n",
            "3. What does the Big Mac Pay Gap Index show?\n",
            "\n",
            "Questions for Text Chunk 3:\n",
            "**True or False Questions:**\n",
            "\n",
            "1. True or False: The Big Mac Index is only available for countries with McDonald's restaurants.\n",
            "\n",
            "**Multiple Choice Questions (MCQ):**\n",
            "\n",
            "1. Which of the following countries is NOT mentioned in the text as having a McDonald's restaurant?\n",
            "   (a) Morocco\n",
            "   (b) India\n",
            "   (c) United States\n",
            "   (d) Kenya\n",
            "\n",
            "2. What is the name of the index used to measure the cost of living in Africa?\n",
            "   (a) Big Mac Index\n",
            "   (b) KFC Index\n",
            "   (c) McDonald's Index\n",
            "   (d) Africa Index\n",
            "\n",
            "3. According to the text, what is a major factor influencing the price of a Big Mac in different countries?\n",
            "   (a) Exchange rates\n",
            "   (b) Local production costs\n",
            "   (c) Social status\n",
            "   (d) Import duties\n",
            "\n",
            "4. Which of the following is NOT mentioned as a reason for the variation in Big Mac prices within a country?\n",
            "   (a) Urban vs. rural location\n",
            "   (b) Cost of ingredients\n",
            "   (c) Business dining expenses\n",
            "   (d) Currency values\n",
            "\n",
            "**One-word Answer Questions:**\n",
            "\n",
            "1. What is the name of the fast-food chain used in the Big Mac Index?\n",
            "2. What is the name of the city mentioned as having the most expensive Big Macs?\n",
            "3. What is the name of the index used to measure the cost of non-tradable goods and services?\n",
            "\n",
            "Questions for Text Chunk 4:\n",
            "**True or False Questions:**\n",
            "\n",
            "1. The Economist magazine supports the claims that Argentina's government has falsified inflation data.\n",
            "2. McDonald's restaurants in Argentina stopped selling Big Macs altogether.\n",
            "\n",
            "**Multiple Choice Questions (MCQ):**\n",
            "\n",
            "1. Which of the following is NOT mentioned as a reason for the closing of McDonald's in Iceland?\n",
            "   (a) High cost of importing meat and vegetables\n",
            "   (b) Lack of local demand for beef\n",
            "   (c) Government regulations\n",
            "   (d) Currency devaluation\n",
            "\n",
            "2. Which country has the most expensive Big Mac according to the text?\n",
            "   (a) Argentina\n",
            "   (b) Switzerland\n",
            "   (c) Norway\n",
            "   (d) Uruguay\n",
            "\n",
            "**One-word Answer Questions:**\n",
            "\n",
            "1. What is the name of the government official who allegedly forced McDonald's to sell the Big Mac at an artificially low price?\n",
            "2. What is the name of the substitute for the Big Mac in India?\n",
            "3. What ingredient is missing from the Big Mac in India?\n",
            "\n",
            "Questions for Text Chunk 5:\n",
            "**True or False Questions:**\n",
            "1. The Big Mac is the least expensive in Egypt. (False)\n",
            "2. It takes less time to earn enough money to buy a Big Mac in Tokyo than in Zurich. (False)\n",
            "3. The Philippines is one of the slowest places to earn enough money to buy a Big Mac. (True)\n",
            "\n",
            "**Multiple Choice Questions (MCQ):**\n",
            "1. Which of the following is the cheapest place to buy a Big Mac?\n",
            "   (a) South Africa\n",
            "   (b) Taiwan\n",
            "   (c) Egypt\n",
            "   (d) India\n",
            "2. In which city does it take the longest to earn enough money to buy a Big Mac?\n",
            "   (a) Nairobi\n",
            "   (b) Manila\n",
            "   (c) Mexico City\n",
            "   (d) Cairo\n",
            "3. How much does a Big Mac cost in Indonesia?\n",
            "   (a) $2.39\n",
            "   (b) $2.52\n",
            "   (c) $2.62\n",
            "   (d) $2.82\n",
            "\n",
            "**One-word Answer Questions:**\n",
            "1. What is the currency of Taiwan? (TWD)\n",
            "2. Which country has the fastest time to earn enough money to buy a Big Mac? (Hong Kong)\n",
            "3. What is the average working time required to buy a Big Mac in Jakarta in 2015? (66.7 min)\n",
            "\n"
          ]
        }
      ],
      "source": [
        "from langchain.document_loaders import PyPDFLoader\n",
        "from langchain.text_splitter import CharacterTextSplitter\n",
        "from langchain.chains import LLMChain\n",
        "from langchain.prompts import PromptTemplate\n",
        "from langchain_google_genai import GoogleGenerativeAI\n",
        "\n",
        "def generate_questions(pdf_path, api_key):\n",
        "    # Load the PDF document\n",
        "    loader = PyPDFLoader(pdf_path)\n",
        "    documents = loader.load()\n",
        "\n",
        "    # Split the text into chunks\n",
        "    text_splitter = CharacterTextSplitter(chunk_size=100, chunk_overlap=0)\n",
        "    texts = text_splitter.split_documents(documents)\n",
        "\n",
        "    # Define the prompt template\n",
        "    prompt_template = \"\"\"\n",
        "    Given the following text, generate multiple questions of three or more types as follows:\n",
        "    1. True or False question\n",
        "    2. Multiple Choice Question (MCQ) with four options\n",
        "    3. One-word answer question\n",
        "\n",
        "    Text:\n",
        "    {text}\n",
        "\n",
        "    Questions:\n",
        "    \"\"\"\n",
        "\n",
        "    prompt = PromptTemplate(template=prompt_template, input_variables=[\"text\"])\n",
        "\n",
        "    # Initialize the Google Language Model\n",
        "    llm = GoogleGenerativeAI(model=\"gemini-pro\", google_api_key=api_key)\n",
        "\n",
        "    # Create the question generation chain\n",
        "    question_chain = LLMChain(llm=llm, prompt=prompt)\n",
        "\n",
        "    # Generate questions for each text chunk\n",
        "    for i, text in enumerate(texts):\n",
        "        print(f\"Questions for Text Chunk {i+1}:\")\n",
        "        response = question_chain.run(text=text.page_content)\n",
        "        print(response)\n",
        "        print()\n",
        "\n",
        "# Provide the path to your sample PDF file\n",
        "pdf_path = \"/content/Big Mac Index.pdf\"\n",
        "\n",
        "# Provide your Google API key\n",
        "api_key = \"YOUR API\"\n",
        "\n",
        "# Generate questions and answers\n",
        "generate_questions(pdf_path, api_key)"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "# CODE TO RUN APP on STREAMLIT"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": 26,
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "AykrZZ1BonCZ",
        "outputId": "a64b235a-63a5-412e-e315-94cd1e6da318"
      },
      "outputs": [
        {
          "name": "stdout",
          "output_type": "stream",
          "text": [
            "Collecting streamlit\n",
            "  Downloading streamlit-1.33.0-py2.py3-none-any.whl (8.1 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m8.1/8.1 MB\u001b[0m \u001b[31m21.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: altair<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.2.2)\n",
            "Requirement already satisfied: blinker<2,>=1.0.0 in /usr/lib/python3/dist-packages (from streamlit) (1.4)\n",
            "Requirement already satisfied: cachetools<6,>=4.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (5.3.3)\n",
            "Requirement already satisfied: click<9,>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.1.7)\n",
            "Requirement already satisfied: numpy<2,>=1.19.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (1.25.2)\n",
            "Requirement already satisfied: packaging<25,>=16.8 in /usr/local/lib/python3.10/dist-packages (from streamlit) (23.2)\n",
            "Requirement already satisfied: pandas<3,>=1.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.0.3)\n",
            "Requirement already satisfied: pillow<11,>=7.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (9.4.0)\n",
            "Requirement already satisfied: protobuf<5,>=3.20 in /usr/local/lib/python3.10/dist-packages (from streamlit) (3.20.3)\n",
            "Requirement already satisfied: pyarrow>=7.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (14.0.2)\n",
            "Requirement already satisfied: requests<3,>=2.27 in /usr/local/lib/python3.10/dist-packages (from streamlit) (2.31.0)\n",
            "Requirement already satisfied: rich<14,>=10.14.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (13.7.1)\n",
            "Requirement already satisfied: tenacity<9,>=8.1.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (8.2.3)\n",
            "Requirement already satisfied: toml<2,>=0.10.1 in /usr/local/lib/python3.10/dist-packages (from streamlit) (0.10.2)\n",
            "Requirement already satisfied: typing-extensions<5,>=4.3.0 in /usr/local/lib/python3.10/dist-packages (from streamlit) (4.11.0)\n",
            "Collecting gitpython!=3.1.19,<4,>=3.0.7 (from streamlit)\n",
            "  Downloading GitPython-3.1.43-py3-none-any.whl (207 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m207.3/207.3 kB\u001b[0m \u001b[31m22.1 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hCollecting pydeck<1,>=0.8.0b4 (from streamlit)\n",
            "  Downloading pydeck-0.8.1b0-py2.py3-none-any.whl (4.8 MB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m4.8/4.8 MB\u001b[0m \u001b[31m50.3 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: tornado<7,>=6.0.3 in /usr/local/lib/python3.10/dist-packages (from streamlit) (6.3.3)\n",
            "Collecting watchdog>=2.1.5 (from streamlit)\n",
            "  Downloading watchdog-4.0.0-py3-none-manylinux2014_x86_64.whl (82 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m83.0/83.0 kB\u001b[0m \u001b[31m9.7 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: entrypoints in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.4)\n",
            "Requirement already satisfied: jinja2 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (3.1.3)\n",
            "Requirement already satisfied: jsonschema>=3.0 in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (4.19.2)\n",
            "Requirement already satisfied: toolz in /usr/local/lib/python3.10/dist-packages (from altair<6,>=4.0->streamlit) (0.12.1)\n",
            "Collecting gitdb<5,>=4.0.1 (from gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading gitdb-4.0.11-py3-none-any.whl (62 kB)\n",
            "\u001b[2K     \u001b[90m━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[32m62.7/62.7 kB\u001b[0m \u001b[31m6.0 MB/s\u001b[0m eta \u001b[36m0:00:00\u001b[0m\n",
            "\u001b[?25hRequirement already satisfied: python-dateutil>=2.8.2 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2.8.2)\n",
            "Requirement already satisfied: pytz>=2020.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2023.4)\n",
            "Requirement already satisfied: tzdata>=2022.1 in /usr/local/lib/python3.10/dist-packages (from pandas<3,>=1.3.0->streamlit) (2024.1)\n",
            "Requirement already satisfied: charset-normalizer<4,>=2 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.3.2)\n",
            "Requirement already satisfied: idna<4,>=2.5 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (3.7)\n",
            "Requirement already satisfied: urllib3<3,>=1.21.1 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2.0.7)\n",
            "Requirement already satisfied: certifi>=2017.4.17 in /usr/local/lib/python3.10/dist-packages (from requests<3,>=2.27->streamlit) (2024.2.2)\n",
            "Requirement already satisfied: markdown-it-py>=2.2.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (3.0.0)\n",
            "Requirement already satisfied: pygments<3.0.0,>=2.13.0 in /usr/local/lib/python3.10/dist-packages (from rich<14,>=10.14.0->streamlit) (2.16.1)\n",
            "Collecting smmap<6,>=3.0.1 (from gitdb<5,>=4.0.1->gitpython!=3.1.19,<4,>=3.0.7->streamlit)\n",
            "  Downloading smmap-5.0.1-py3-none-any.whl (24 kB)\n",
            "Requirement already satisfied: MarkupSafe>=2.0 in /usr/local/lib/python3.10/dist-packages (from jinja2->altair<6,>=4.0->streamlit) (2.1.5)\n",
            "Requirement already satisfied: attrs>=22.2.0 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (23.2.0)\n",
            "Requirement already satisfied: jsonschema-specifications>=2023.03.6 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (2023.12.1)\n",
            "Requirement already satisfied: referencing>=0.28.4 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.34.0)\n",
            "Requirement already satisfied: rpds-py>=0.7.1 in /usr/local/lib/python3.10/dist-packages (from jsonschema>=3.0->altair<6,>=4.0->streamlit) (0.18.0)\n",
            "Requirement already satisfied: mdurl~=0.1 in /usr/local/lib/python3.10/dist-packages (from markdown-it-py>=2.2.0->rich<14,>=10.14.0->streamlit) (0.1.2)\n",
            "Requirement already satisfied: six>=1.5 in /usr/local/lib/python3.10/dist-packages (from python-dateutil>=2.8.2->pandas<3,>=1.3.0->streamlit) (1.16.0)\n",
            "Installing collected packages: watchdog, smmap, pydeck, gitdb, gitpython, streamlit\n",
            "Successfully installed gitdb-4.0.11 gitpython-3.1.43 pydeck-0.8.1b0 smmap-5.0.1 streamlit-1.33.0 watchdog-4.0.0\n"
          ]
        }
      ],
      "source": [
        "!pip install streamlit"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "Lr6FR3NCxg3y"
      },
      "source": []
    },
    {
      "cell_type": "markdown",
      "metadata": {
        "id": "rs7f4jwLxhjp"
      },
      "source": []
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "qj7n6SCry0Sj"
      },
      "outputs": [],
      "source": [
        "!wget -q -O - ipv4.icanhazip.com"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "Copy paste the above output as password for tunnel"
      ]
    },
    {
      "cell_type": "markdown",
      "metadata": {},
      "source": [
        "#After running this use the link in \"your url is: \" and enter password there\n",
        "!streamlit run app.py & npx localtunnel --port 8501"
      ]
    },
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {},
      "outputs": [],
      "source": []
    }
  ],
  "metadata": {
    "colab": {
      "provenance": []
    },
    "kernelspec": {
      "display_name": "Python 3",
      "name": "python3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "nbformat": 4,
  "nbformat_minor": 0
}
